Dataflow:
Traffic-> Ingress Service -> ClusterIPService -> Deployment of anything-> Pods

Workflow:
Create config files for everything -> test on local -> GitHub and Travis CI/CD flow -> Deploy App

ClusterIPService: Exposes a set of pods to other objects in the cluster (more restrictive)
NodePort: Exposes a set of pods to the outside world

** Can combine seperate files into single (clusterIP and deployment) --> seperate with ---

--------------------------------------------------------------------------------------------------------------------

Databases and Persistent Volumes:

- Why? : Postgres or any database maintains data into a file system. If the container inside pod crashes, the data is also lost.

- How? : The Postgres container inside the pod writes to the volumes on host machine(hard disk). Don't increase the replicas of Postgres as accessing the same volume from different containers may be disastrous.

- Volume in Kubernetes: An object allowing a container to store data at the pod level.(different from Docker Volumes) If a pod is somehow deleted or recreated, the data associated with the volume inside the pod also goes away.

- Persistent Volume in K8s : An object allowing a container to store data outside the pod level.(longtime-durable)

- Persistent Volume Claim (PVC) : provides options for Statically or Dynamically provisioned Persistent Volume. 
This is attached to a pod-config(doesn't allocate the requested storage). K8s sees this and checks for Static Prov PVs. If not, it creates on-the-fly Dynamic prov PV for the requested requirement and allocates an instance of the storage.
Three access modes:
ReadWriteOnce-> can be used by a single node
ReadOnlyMany-> multiple nodes can read from this
ReadWriteMany-> can be read and written to by many nodes

Where does it store? : It creates a slice of yout hard drive using a provisioner ( kubectl get storageclass )
Read the k8s docs about the storage class to know more about the specific config required for the cloud storage providers

--------------------------------------------------------------------------------------------------------------------
Designating a PVC into the pod template: 
mention the volume part inside the spec section and put the PVC details there. (see postgres-deployment.yaml)
once assigned, use the same key-value pair inside volumeMount with the mountPath
--------------------------------------------------------------------------------------------------------------------
Environment variables:

multi-worker needs: REDIS_HOST and REDIS_PORT
multi-server needs: PGHOST,PGUSER,PGDATABASE,PGPORT,PGPASSWORD

for PGPASSWORD: use an imperative command to create the secret
kubectl create secret generic <secret-name> --from-literal key=value
--------------------------------------------------------------------------------------------------------------------

Load Balancer Service: legacy way of getting network traffic into the cluster from outside.
-> allows access to one specific set of pods only. -> provisioned externally and automatically

--------------------------------------------------------------------------------------------------------------------

Ingress Controllers: exposes a set of services to the outside world. (outside to the clusterIP)
-> several implementations (using ingress-nginx here not kubernetes-nginx)
-> setup of ingress-nginx changes according to each environment.
-> basic idea is that the ingress controller gets our desired state(routing rules to get traffic to services) from the ingress config and the it creates a pod running nginx that handles routing.
-> ingress also creates a default backend pod(deployment and clusterIP) to get the health status of the cluster
-> advantage is the extra features as opposed to confugring a nginx pod by ourself. Directly routes traffic to the pods enabling sticky sessions(same user,request goes to same server again)

Traffic -> Google Cloud Load Balancer -> Load Balancer Service (Powered by ingress-nginx ) ie. a load balancer service and a nginx controller deployment

Install Ingress (local): 
kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/static/mandatory.yaml
kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/static/provider/cloud-generic.yaml

Configuration file : ingress-service.yaml
